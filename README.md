# Data_extraction_llm
Leveraging Large language models (LLM), extract information from the documents.

This project utilizes the Mistral-7B quantized model, a powerful large language model (LLM), to effectively extract key information from diverse documents.

# installation
```python
!pip3 install --upgrade auto-gptq
!pip3 install --upgrade transformers optimum
!pip install paddlepaddle-gpu
!pip install paddleocr
```
# Note : Quantized gptq model runs only in GPU environment . Use ggml or gguf versions for cpu based inference.
